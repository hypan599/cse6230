{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Performance Metrics & First Week Flop/s\n",
    "\n",
    "This assignment has some questions that you need to answer with text, and some code that you need to write.\n",
    "\n",
    "You should put all of you textual answers in this notebook: `Insert->Insert Cell Below` to create a new cell below\n",
    "the question, and `Cell->Cell Type->Markdown` to make it a cell for entering text.\n",
    "\n",
    "You will test your code on the compute nodes of pace-ice, and that it also where we will evaluate it.\n",
    "Please complete the text portions when you are logged into a head node working locally, and leave the compute nodes for when you actually need them.\n",
    "\n",
    "**Due: Tuesday, September 2, 9:30 am**\n",
    "\n",
    "**Total: 10 pts + 2 bonus pts (1 for working on a node with GPUs, 1 for optimizing the flop/s code)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Metrics\n",
    "\n",
    "In class we talked about the _strong-scaling efficiency_ of a parallel algorithm / machine pair: $H_f(P) = T_f(1) / (P T_f(P))$.\n",
    "\n",
    "We then talked about the _weak-scaling efficiency_ of algorithm $f$ that can be applied to different problem sizes $N$: $E_f(N,P) = T_f(N/P,1) / T_f(N,P)$.\n",
    "\n",
    "The question came up of how they are related to each other.\n",
    "\n",
    "First, the notion of strong scaling doesn't have a concept of problem size, so let's add it: let's define\n",
    "\n",
    "$$H_f(N,P) = T_f(N,1) / (P T_f(N,P)).$$\n",
    "\n",
    "This is simply strong-scaling efficiency for each problem instance individually.\n",
    "\n",
    "**Question 1 (1 pt):** Show that the relative order of strong and weak scaling efficiency (Whether $H_f(N,P) < E_f(N,P)$ or $E_f(N,P) < H_f(N,P)$) can be related to the efficiency of the serial algorithm, that is, whether $T_f(N,1)$ as a function of $N$ exhibits superlinear or sublinear behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PACE-ICE\n",
    "\n",
    "**Head node exercise 1 (1 pt):** What command should you run from a head node to see a list of all the compute nodes in `coc-ice` and their availability? [Resource for this question: the [orientation slides](http://pace.gatech.edu/sites/default/files/pace-ice_orientation_2.pdf)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### queues\n",
    "- coc-ice\n",
    "- coc-ice-gpu\n",
    "- coc-ice-multi\n",
    "- coc-ice-long\n",
    "- coc-ice-grade\n",
    "- coc-ice-devel\n",
    "\n",
    "qsub qdel showq qstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t** NEW FEATURE : add '-s' to pace-check-queue to list \n",
      "\t** scheduler features for each node\n",
      "\n",
      "=== coc-ice Queue Summary: ====\n",
      "\tLast Update                            : 08/30/2019 09:00:02\n",
      "\tNumber of Nodes (Accepting Jobs/Total) : 48/49 (97.96%)\n",
      "\tNumber of Cores (Used/Total)           : 1/916 ( 0.11%)\n",
      "\tAmount of Memory (Used/Total) (MB)     : 118809/8105865 ( 1.47%)\n",
      "=================================================================================\n",
      "  Hostname       tasks/np Cpu%  loadav%  used/totmem(MB)   Mem%   Accepting Jobs? \n",
      "=================================================================================\n",
      "rich133-h35-15-r   1/28    3.6     0.8      2920/131126     2.2    Yes (free)             \n",
      "rich133-h35-16-l   0/28    0.0     0.3      2885/131126     2.2    Yes (free)             \n",
      "rich133-h35-16-r   0/28    0.0     1.0      2907/131126     2.2    Yes (free)             \n",
      "rich133-h35-17-l   0/28    0.0     1.0      5037/518966     1.0    Yes (free)             \n",
      "rich133-h35-17-r   0/28    0.0     0.2      5034/518966     1.0    Yes (free)             \n",
      "rich133-h35-18-l   0/28    0.0     0.7      5063/518966     1.0    Yes (free)             \n",
      "rich133-h35-18-r   0/28    0.0     0.6      4988/518966     1.0    Yes (free)             \n",
      "rich133-k33-17     0/8     0.0     2.1      3541/260408     1.4    Yes (free)             \n",
      "rich133-k40-17     0/8     0.0     1.0      2776/131128     2.1    Yes (free)             \n",
      "rich133-k40-18     0/8     0.0     2.0      2774/131128     2.1    Yes (free)             \n",
      "rich133-k40-20-l   0/28    0.0     0.2      2986/131126     2.3    Yes (free)             \n",
      "rich133-k40-20-r   0/28    0.0     1.0      2832/131126     2.2    Yes (free)             \n",
      "rich133-k40-21-l   0/28    0.0     0.3      2754/131126     2.1    Yes (free)             \n",
      "rich133-k40-21-r   0/28    0.0     1.6      2851/131126     2.2    Yes (free)             \n",
      "rich133-k40-22-l   0/28    0.0     1.1      2838/131126     2.2    Yes (free)             \n",
      "rich133-k40-22-r   0/28    0.0     0.2      2896/131126     2.2    Yes (free)             \n",
      "rich133-k40-23-l   0/28    0.0     0.5      2870/131126     2.2    Yes (free)             \n",
      "rich133-k40-23-r   0/28    0.0     0.2      2843/131126     2.2    Yes (free)             \n",
      "rich133-k40-24-l   0/28    0.0     0.7      2839/131126     2.2    Yes (free)             \n",
      "rich133-k40-24-r   0/28    0.0     0.5      2822/131126     2.2    Yes (free)             \n",
      "rich133-k40-25-l   0/28    0.0     0.7      2874/131126     2.2    Yes (free)             \n",
      "rich133-k40-25-r   0/28    0.0     1.0      2788/131126     2.1    Yes (free)             \n",
      "rich133-k40-26-l   0/28    0.0     0.0      2954/131126     2.3    Yes (free)             \n",
      "rich133-k40-26-r   0/28    0.0     0.6      2795/131126     2.1    Yes (free)             \n",
      "rich133-k40-27-l   0/28    0.0     0.6      2929/131126     2.2    Yes (free)             \n",
      "rich133-k40-27-r   0/28    0.0     0.7      2842/131126     2.2    Yes (free)             \n",
      "rich133-k40-29     0/8     0.0     2.1      2822/131128     2.2    Yes (free)             \n",
      "rich133-k40-30     0/8     0.0     0.1      2729/131128     2.1    Yes (free)             \n",
      "rich133-s30-10     0/12    0.0     0.8      1240/131128     0.9    Yes (free)             \n",
      "rich133-s30-11     0/12    0.0     1.9      1420/131128     1.1    Yes (free)             \n",
      "rich133-s30-12     0/12    0.0     1.8      1470/131128     1.1    Yes (free)             \n",
      "rich133-s30-13     0/12    0.0     0.2      1399/131128     1.1    Yes (free)             \n",
      "rich133-s30-14     0/12    0.0     2.7      1434/131128     1.1    Yes (free)             \n",
      "rich133-s30-15     0/12    0.0     1.8      1479/131128     1.1    Yes (free)             \n",
      "rich133-s30-16     0/12    0.0     6.5      1483/131128     1.1    Yes (free)             \n",
      "rich133-s30-17     0/12    0.0     3.0      1422/131128     1.1    Yes (free)             \n",
      "rich133-s30-18     0/12    0.0     0.5      1431/131128     1.1    Yes (free)             \n",
      "rich133-s30-19     0/12    0.0     3.6      1490/131128     1.1    Yes (free)             \n",
      "rich133-s30-20     0/24    0.0     0.2      1139/131127     0.9    No  (node down or offline) \n",
      "rich133-s30-21     0/12    0.0     0.8      1489/131128     1.1    Yes (free)             \n",
      "rich133-s30-22     0/12    0.0     0.5      1424/131128     1.1    Yes (free)             \n",
      "rich133-s42-21     0/8     0.0     0.2      1367/131128     1.0    Yes (free)             \n",
      "rich133-s42-22     0/8     0.0     1.2      1395/131128     1.1    Yes (free)             \n",
      "rich133-s42-23     0/8     0.0     2.0      1444/131128     1.1    Yes (free)             \n",
      "rich133-s42-24     0/8     0.0     2.6      1415/131128     1.1    Yes (free)             \n",
      "rich133-s42-25     0/8     0.0     2.9      1444/131128     1.1    Yes (free)             \n",
      "rich133-s42-26     0/8     0.0     1.2      1396/131128     1.1    Yes (free)             \n",
      "rich133-s42-27     0/8     0.0     1.8      1445/131128     1.1    Yes (free)             \n",
      "rich133-s42-28     0/8     0.0     0.9      1394/131128     1.1    Yes (free)             \n"
     ]
    }
   ],
   "source": [
    "# <-- Put your command there\n",
    "pace-check-queue coc-ice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try it out: open up this notebook on a head node and compare the list you get to the [orientation slides](http://pace.gatech.edu/sites/default/files/pace-ice_orientation_2.pdf).  You'll see that it has grown, and they haven't updated the orientation slides.  We'll just have to find out what all these new nodes are for ourselves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### A word on running jupyter on pace-ice:\n",
    "\n",
    "As we discussed in class, screen refresh can be a bit laggy if you try to run a jupyter notebook through a browser opened on the head node or a compute node.  See the [guide](../../notes/logistics/compute-node-notebook.ipynb) in the notes for instructions on runnin the jupyter server on the compute nodes and the browser on your own computer.  You don't have to work directly in the notebook: you can work on you answers in the terminal, and then paste them into the notebook, as long as you're confident that they are correct.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Head node exercise 2 (1 pt):** From the output of the above answer, you can probably see that we have a few different types of nodes to work with.  Fill in the blanks in the list below, describing the _properties_ of the different types. [Command line tools you might want to use: `qnodes`, `grep`, `sort`]\n",
    "\n",
    "1. **24** nodes with **28** CPU core(s) and no GPUs\n",
    "2. **12** nodes with **12** CPU core(s) and **2** GPU(s) of type NVIDIA Tesla **K40**.\n",
    "3. **25** nodes with **8** CPU core(s) and **1** GPU(s) of type NVIDIA Tesla **P100** (this group includes `rich133-s42-21.pace.gatech.edu`, even though that the type of GPU is not listed for this node)\n",
    "5. One node (`rich133-s30-20.pace.gatech.edu`) with **24** CPU core(s) (currently offline)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    "qnodes | grep properties | sort | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     power_state = Running\n",
      "     np = 12\n",
      "     properties = core12,mhz2400,ib,ibQDR,localdisk,nvidiagpu,teslak40,ssd,5-2620v3,intel,rhel6\n",
      "     ntype = cluster\n",
      "     status = rectime=1567171958,macaddr=40:8d:5c:d4:eb:8b,cpuclock=Fixed,varattr=,jobs=,state=free,size=87592724kb:88117536kb,netload=3685577401,gres=,loadave=0.09,ncpus=12,physmem=132178344kb,availmem=132814684kb,totmem=134275492kb,idletime=1875434,nusers=0,nsessions=0,uname=Linux rich133-s30-22.pace.gatech.edu 2.6.32-573.12.1.el6.x86_64 #1 SMP Mon Nov 23 12:55:32 EST 2015 x86_64,opsys=RHEL6.7\n",
      "     mom_service_port = 15002\n",
      "     mom_manager_port = 15003\n",
      "     gpus = 2\n",
      "     gpu_status = gpu[1]=gpu_id=00000000:81:00.0;gpu_product_name=Tesla K40m;gpu_display=Disabled;gpu_pci_device_id=102310DE;gpu_pci_location_id=00000000:81:00.0;gpu_fan_speed=N/A;gpu_mode=Exclusive_Process;gpu_state=Unallocated;gpu_utilization=0 %;gpu_memory_utilization=0 %;gpu_ecc_mode=Enabled;gpu_single_bit_ecc_errors=1;gpu_double_bit_ecc_errors=1;gpu_temperature=29 C,gpu[0]=gpu_id=00000000:02:00.0;gpu_product_name=Tesla K40m;gpu_display=Disabled;gpu_pci_device_id=102310DE;gpu_pci_location_id=00000000:02:00.0;gpu_fan_speed=N/A;gpu_mode=Exclusive_Process;gpu_state=Unallocated;gpu_utilization=0 %;gpu_memory_utilization=0 %;gpu_ecc_mode=Enabled;gpu_single_bit_ecc_errors=1;gpu_double_bit_ecc_errors=1;gpu_temperature=20 C,driver_ver=390.30,timestamp=Fri Aug 30 09:32:38 2019\n",
      "\n",
      "rich133-s42-21.pace.gatech.edu\n",
      "     state = free\n",
      "     power_state = Running\n",
      "     np = 8\n",
      "     properties = core8,mhz2600,ib,ibQDR,localdisk,ssd,5-2623v4,intel,rhel6\n",
      "     ntype = cluster\n",
      "     status = rectime=1567171982,macaddr=1c:1b:0d:b4:10:14,cpuclock=Fixed,varattr=,jobs=,state=free,size=108942180kb:109271976kb,netload=3703415348,gres=,loadave=0.00,ncpus=8,physmem=132178848kb,availmem=132860560kb,totmem=134275996kb,idletime=681669,nusers=0,nsessions=0,uname=Linux rich133-s42-21.pace.gatech.edu 2.6.32-573.12.1.el6.x86_64 #1 SMP Mon Nov 23 12:55:32 EST 2015 x86_64,opsys=RHEL6.7\n",
      "     mom_service_port = 15002\n",
      "     mom_manager_port = 15003\n",
      "     gpus = 1\n",
      "     gpu_status = gpu[0]=gpu_id=00000000:02:00.0;gpu_product_name=Tesla P100-PCIE-16GB;gpu_display=Enabled;gpu_pci_device_id=15F810DE;gpu_pci_location_id=00000000:02:00.0;gpu_fan_speed=N/A;gpu_mode=Default;gpu_state=Unallocated;gpu_utilization=0 %;gpu_memory_utilization=0 %;gpu_ecc_mode=Enabled;gpu_single_bit_ecc_errors=0;gpu_double_bit_ecc_errors=0;gpu_temperature=26 C,driver_ver=390.30,timestamp=Fri Aug 30 09:33:01 2019\n",
      "\n",
      "rich133-s42-22.pace.gatech.edu\n",
      "     state = free\n",
      "     power_state = Running\n",
      "     np = 8\n",
      "     properties = core8,mhz2600,ib,ibQDR,localdisk,nvidiagpu,teslap100,ssd,5-2623v4,intel,rhel6\n"
     ]
    }
   ],
   "source": [
    "qnodes | grep -10 rich133-s42-21.pace.gatech.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Head node exercise 3 (1 pt):** For the next questions, I need you to log in to compute nodes to find out about them, but you need to be able to specify which type of compute nodes you are accessing.\n",
    "\n",
    "For each of the types of nodes 1, 2, and 3 in the question above, give me a `qsub` command to start a `jupyter_notebook_script.sh` job on that type of node, with the following requirements:\n",
    "\n",
    "* The job should give you exclusive access to one node and all its cores and devices.\n",
    "* The job should begin in the CSE6230 directory.\n",
    "* The job should end after 30 minutes.\n",
    "\n",
    "[Resources: [compute-node-notebook.ipynb](../../notes/logistics/compute-node-notebook.ipynb), [orientation slides](http://pace.gatech.edu/sites/default/files/pace-ice_orientation_2.pdf)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qsub(1B)                              PBS                             qsub(1B)\n",
      "\n",
      "\n",
      "\n",
      "NAME\n",
      "       qsub - submit pbs job\n",
      "\n",
      "SYNOPSIS\n",
      "       qsub   [-a   date_time]   [-A  account_string]  [-b  secs]  [-c  check-\n",
      "       point_options] [-C directive_prefix] [-d path] [-D path] [-e path] [-f]\n",
      "       [-h]  [-I] [-j join] [-k keep] [-l resource_list] [-m mail_options] [-M\n",
      "       user_list] [-n node exclusive] [-N name] [-o path]  [-p  priority]  [-P\n",
      "       proxy_username[:group]]   [-q  destination]  [-r  c] [-S path_list] [-t\n",
      "       array_request] [-T prologue/epilogue script_name]  [-u  user_list]  [-v\n",
      "       variable_list] [-V] [-w] path [-W additional_attributes] [-x] [-X] [-z]\n",
      "       [script]\n",
      "\n",
      "DESCRIPTION\n",
      "       To create a job is to submit an executable script to  a  batch  server.\n",
      "       The  batch  server  will  be the default server unless the -q option is\n",
      "       specified.  See discussion of PBS_DEFAULT under  Environment  Variables\n",
      "       below.   Typically, the script is a shell script which will be executed\n",
      "       by a command shell such as sh or csh.\n",
      "\n",
      "       Options on the qsub command allow the specification of attributes which\n",
      "       affect the behavior of the job.\n",
      "\n",
      "       The  qsub  command will pass certain environment variables in the Vari-\n",
      "       able_List attribute of the job.  These variables will be  available  to\n",
      "       the  job.  The value for the following variables will be taken from the\n",
      "       environment of the qsub  command:  HOME,  LANG,  LOGNAME,  PATH,  MAIL,\n",
      "       SHELL,  and  TZ.   These values will be assigned to a new name which is\n",
      "       the current name prefixed with the string \"PBS_O_\".  For  example,  the\n",
      "       job  will have access to an environment variable named PBS_O_HOME which\n",
      "       have the value of the variable HOME in the qsub command environment.\n",
      "\n",
      "       In addition to the above, the following environment variables  will  be\n",
      "       available to the batch job.\n",
      "\n",
      "       PBS_O_HOST\n",
      "              the name of the host upon which the qsub command is running.\n",
      "\n",
      "       PBS_SERVER\n",
      "              the hostname of the pbs_server which qsub submits the job to.\n",
      "\n",
      "       PBS_O_QUEUE\n",
      "              the name of the original queue to which the job was submitted.\n",
      "\n",
      "       PBS_O_WORKDIR\n",
      "              the  absolute  path of the current working directory of the qsub\n",
      "              command.\n",
      "\n",
      "       PBS_ARRAYID\n",
      "              each member of a job array is assigned a unique identifier  (see\n",
      "              -t)\n",
      "\n",
      "       PBS_ENVIRONMENT\n",
      "              set  to  PBS_BATCH  to  indicate  the  job is a batch job, or to\n",
      "              PBS_INTERACTIVE to indicate the job is a  PBS  interactive  job,\n",
      "              see -I option.\n",
      "\n",
      "       PBS_JOBID\n",
      "              the job identifier assigned to the job by the batch system.\n",
      "\n",
      "       PBS_JOBNAME\n",
      "              the job name supplied by the user.\n",
      "\n",
      "       PBS_NODEFILE\n",
      "              the  name  of the file contain the list of nodes assigned to the\n",
      "              job (for parallel and cluster systems).\n",
      "\n",
      "       PBS_QUEUE\n",
      "              the name of the queue from which the job is executed.\n",
      "\n",
      "OPTIONS\n",
      "       -a date_time\n",
      "               Declares the time after which the job is  eligible  for  execu-\n",
      "               tion.\n",
      "\n",
      "               The      date_time     argument     is     in     the     form:\n",
      "               [[[[CC]YY]MM]DD]hhmm[.SS]\n",
      "\n",
      "               Where CC is the first two digits of the year (the century),  YY\n",
      "               is  the second two digits of the year, MM is the two digits for\n",
      "               the month, DD is the day of the month, hh is the  hour,  mm  is\n",
      "               the minute, and the optional SS is the seconds.\n",
      "\n",
      "               If the month, MM, is not specified, it will default to the cur-\n",
      "               rent month if the specified day DD, is in the  future.   Other-\n",
      "               wise,  the  month  will be set to next month.  Likewise, if the\n",
      "               day, DD, is not specified, it will default to today if the time\n",
      "               hhmm  is  in  the  future.   Otherwise,  the day will be set to\n",
      "               tomorrow.  For example, if you submit a job at 11:15am  with  a\n",
      "               time  of  -a  1110,  the job will be eligible to run at 11:10am\n",
      "               tomorrow.\n",
      "\n",
      "       -A account_string\n",
      "               Defines the  account  string  associated  with  the  job.   The\n",
      "               account_string  is  an  undefined  string  of characters and is\n",
      "               interpreted by the server which executes the job.  See  section\n",
      "               2.7.1 of the PBS ERS.\n",
      "\n",
      "       -b seconds\n",
      "               Defines  the maximum number of seconds qsub will block attempt-\n",
      "               ing to contact pbs_server.  If pbs_server is  down,  or  for  a\n",
      "               variety  of communication failures, qsub will continually retry\n",
      "               connecting to pbs_server for job submission.  This value  over-\n",
      "               rides  the CLIENTRETRY parameter in torque.cfg.  This is a non-\n",
      "               portable TORQUE extension.  Portability-minded  users  can  use\n",
      "               the  PBS_CLIENTRETRY  environmental variable.  A negative value\n",
      "               is interpreted as infinity.  The default is 0.\n",
      "\n",
      "       -c checkpoint_options\n",
      "               Defines the options that will apply to the  job.   If  the  job\n",
      "               executes  upon  a host which does not support checkpoint, these\n",
      "               options will be ignored.\n",
      "\n",
      "               Valid checkpoint options are:\n",
      "\n",
      "               none\n",
      "                  No checkpointing is to be performed.\n",
      "\n",
      "               enabled\n",
      "                  Specify that checkpointing is allowed but must be explicitly\n",
      "                  invoked by either the qhold or qchkpt commands.\n",
      "\n",
      "               shutdown\n",
      "                  Specify that checkpointing is to be done on a job at pbs_mom\n",
      "                  shutdown.\n",
      "\n",
      "               periodic\n",
      "                  Specify that periodic checkpointing is enabled. The  default\n",
      "                  interval  is  10  minutes  and can be changed by the $check-\n",
      "                  point_interval option in the mom config file or by  specify-\n",
      "                  ing an interval when the job is submitted\n",
      "\n",
      "               interval=minutes\n",
      "                  Checkpointing  is to be performed at an interval of minutes,\n",
      "                  which is the integer number of minutes of wall time used  by\n",
      "                  the job.  This value must be greater than zero.\n",
      "\n",
      "               depth=number\n",
      "                  Specify  a number (depth) of checkpoint images to be kept in\n",
      "                  the checkpoint directory.\n",
      "\n",
      "               dir=path\n",
      "                  Specify    a    checkpoint     directory     (default     is\n",
      "                  /var/spool/torque/checkpoint).\n",
      "\n",
      "       -C directive_prefix\n",
      "               Defines  the  prefix that declares a directive to the qsub com-\n",
      "               mand within the script  file.   See  the  paragraph  on  script\n",
      "               directives in the Extended Description section.\n",
      "\n",
      "               If  the -C option is presented with a directive_prefix argument\n",
      "               that is the null string, qsub will not scan the script file for\n",
      "               directives.\n",
      "\n",
      "       -d path Defines  the working directory path to be used for the job.  If\n",
      "               the -d option is not specified, the default  working  directory\n",
      "               is  the home directory.  This option sets the environment vari-\n",
      "               able PBS_O_INITDIR.\n",
      "\n",
      "       -D path Defines the root directory to be used for the job.  This option\n",
      "               sets the environment variable PBS_O_ROOTDIR.\n",
      "\n",
      "       -e path Defines  the  path  to be used for the standard error stream of\n",
      "               the batch job.  The path argument is of the form:\n",
      "                   [hostname:][path_name]\n",
      "               where hostname is the name of a host to which the file will  be\n",
      "               returned  and  path_name  is  the path name on that host in the\n",
      "               syntax recognized by POSIX.  The argument will  be  interpreted\n",
      "               as follows:\n",
      "\n",
      "               path_name\n",
      "                      Where  path_name  is not an absolute path name, then the\n",
      "                      qsub command will expand the path name relative  to  the\n",
      "                      current  working  directory of the command.  The command\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      will supply the name of the host upon which it  is  exe-\n",
      "                      cuting for the hostname component.\n",
      "\n",
      "               hostname:path_name\n",
      "                      Where  path_name  is not an absolute path name, then the\n",
      "                      qsub command will not expand the path name  relative  to\n",
      "                      the current working directory of the command.  On deliv-\n",
      "                      ery of  the  standard  error,  the  path  name  will  be\n",
      "                      expanded  relative  to  the user’s home directory on the\n",
      "                      hostname system.\n",
      "\n",
      "               path_name\n",
      "                      Where path_name specifies an absolute  path  name,  then\n",
      "                      the qsub will supply the name of the host on which it is\n",
      "                      executing for the hostname\n",
      "\n",
      "               hostname:path_name\n",
      "                      Where path_name specifies an  absolute  path  name,  the\n",
      "                      path will be used as specified.  hostname.\n",
      "\n",
      "               hostname:\n",
      "                      Where  hostname  specifies the name of the host that the\n",
      "                      file should be returned to. The path will be the default\n",
      "                      file name.\n",
      "\n",
      "               If the -e option is not specified or the path_name is not spec-\n",
      "               ified or is specified and is a directory, the default file name\n",
      "               for  the  standard error stream will be used.  The default name\n",
      "               has the following form:\n",
      "                   job_name.esequence_number\n",
      "               where job_name is the name of  the  job,  see  -N  option,  and\n",
      "               sequence_number is the job number assigned when the job is sub-\n",
      "               mitted.\n",
      "\n",
      "       -f      Specifies that the job is fault  tolerant.  The  fault_tolerant\n",
      "               attribute will be set to true, which indicates that the job can\n",
      "               survive the loss of a mom other than the \"mother superior\"  mom\n",
      "               (the first node in the exec hosts )\n",
      "\n",
      "       -h      Specifies  that a user hold be applied to the job at submission\n",
      "               time.\n",
      "\n",
      "       -I      Declares that the job is to be run  \"interactively\".   The  job\n",
      "               will  be  queued  and  scheduled as any PBS batch job, but when\n",
      "               executed, the standard input, output, and error streams of  the\n",
      "               job are connected through qsub to the terminal session in which\n",
      "               qsub is running.  Interactive jobs are forced to not rerunable.\n",
      "               See  the \"Extended Description\" paragraph for addition informa-\n",
      "               tion of interactive jobs.\n",
      "\n",
      "       -j join Declares if the standard error stream of the job will be merged\n",
      "               with the standard output stream of the job.\n",
      "\n",
      "               An  option  argument  value  of oe directs that the two streams\n",
      "               will be merged, intermixed,  as  standard  output.   An  option\n",
      "               argument  value  of  eo  directs  that  the two streams will be\n",
      "               merged, intermixed, as standard error.\n",
      "\n",
      "               If the join argument is n or the option is not  specified,  the\n",
      "               two streams will be two separate files.\n",
      "\n",
      "       -k keep Defines  which (if either) of standard output or standard error\n",
      "               will be retained on the execution host.  If set for  a  stream,\n",
      "               this  option  overrides  the path name for that stream.  If not\n",
      "               set, neither stream is retained on the execution host.\n",
      "\n",
      "               The argument is either the single letter \"e\"  or  \"o\",  or  the\n",
      "               letters  \"e\" and \"o\" combined in either order.  Or the argument\n",
      "               is the letter \"n\".\n",
      "\n",
      "               e  The standard error stream is to retained  on  the  execution\n",
      "                  host.   The   stream will be placed in the home directory of\n",
      "                  the user under whose user id the  job  executed.   The  file\n",
      "                  name  will  be the default file name given by: job_name.ese-\n",
      "                  quence where job_name is the name specified for the job, and\n",
      "                  sequence is the sequence number component of the job identi-\n",
      "                  fier.\n",
      "\n",
      "               o  The standard output stream is to retained on  the  execution\n",
      "                  host.   The   stream will be placed in the home directory of\n",
      "                  the user under whose user id the  job  executed.   The  file\n",
      "                  name  will  be the default file name given by: job_name.ose-\n",
      "                  quence where job_name is the name specified for the job, and\n",
      "                  sequence is the sequence number component of the job identi-\n",
      "                  fier.\n",
      "\n",
      "               eo Both the standard output and standard error streams will  be\n",
      "                  retained.\n",
      "\n",
      "               oe Both  the standard output and standard error streams will be\n",
      "                  retained.\n",
      "\n",
      "               n  Neither stream is retained.\n",
      "\n",
      "       -l resource_list\n",
      "               Defines the resources that are required by the job  and  estab-\n",
      "               lishes  a limit to the amount of resource that can be consumed.\n",
      "               If not set for a generally  available  resource,  such  as  CPU\n",
      "               time,  the limit is infinite.  The resource_list argument is of\n",
      "               the form:\n",
      "                   resource_name[=[value]][,resource_name[=[value]],...]\n",
      "\n",
      "       -m mail_options\n",
      "               Defines the set of conditions under which the execution  server\n",
      "               will send a mail message about the job.  The mail_options argu-\n",
      "               ment is a string which consists of either the single  character\n",
      "               \"n\", or one or more of the characters \"a\", \"b\", and \"e\".\n",
      "\n",
      "               If the character \"n\" is specified, no mail will be sent.\n",
      "\n",
      "               For the letters \"a\", \"b\", and \"e\":\n",
      "\n",
      "               a  mail is sent when the job is aborted by the batch system.\n",
      "\n",
      "               b  mail is sent when the job begins execution.\n",
      "\n",
      "               e  mail is sent when the job terminates.\n",
      "\n",
      "               If the -m option is not specified, mail will be sent if the job\n",
      "               is aborted.\n",
      "\n",
      "       -M user_list\n",
      "               Declares the list of users to whom mail is sent by  the  execu-\n",
      "               tion server when it sends mail about the job.\n",
      "\n",
      "               The user_list argument is of the form:\n",
      "                   user[@host][,user[@host],...]\n",
      "               If  unset, the list defaults to the submitting user at the qsub\n",
      "               host, i.e. the job owner.\n",
      "\n",
      "       -n      Specifies that the job has exclusive access to the nodes it  is\n",
      "               executing on. This is intended to be used in conjunction with a\n",
      "               scheduler that enforces exclusive  access,  and  it  tells  the\n",
      "               cpuset  to give the job access to all of that node’s resources.\n",
      "\n",
      "       -N name Declares a name for the job.  The name specified may be  up  to\n",
      "               and  including  15  characters  in  length.  It must consist of\n",
      "               printable, non white space characters with the first  character\n",
      "               alphabetic.\n",
      "\n",
      "               If  the  -N  option  is not specified, the job name will be the\n",
      "               base name of the job script file specified on the command line.\n",
      "               If  no  script  file name was specified and the script was read\n",
      "               from the standard input, then the  job  name  will  be  set  to\n",
      "               STDIN.\n",
      "\n",
      "       -o path Defines  the  path to be used for the standard output stream of\n",
      "               the batch job.  The path argument is of the form:\n",
      "                   [hostname:][path_name]\n",
      "               where hostname is the name of a host to which the file will  be\n",
      "               returned  and  path_name  is  the path name on that host in the\n",
      "               syntax recognized by POSIX.  The argument will  be  interpreted\n",
      "               as follows:\n",
      "\n",
      "               path_name\n",
      "                      Where  path_name  is not an absolute path name, then the\n",
      "                      qsub command will expand the path name relative  to  the\n",
      "                      current  working  directory of the command.  The command\n",
      "                      will supply the name of the host upon which it  is  exe-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      cuting for the hostname component.\n",
      "\n",
      "               hostname:path_name\n",
      "                      Where  path_name  is not an absolute path name, then the\n",
      "                      qsub command will not expand the path name  relative  to\n",
      "                      the current working directory of the command.  On deliv-\n",
      "                      ery of the  standard  output,  the  path  name  will  be\n",
      "                      expanded  relative  to  the user’s home directory on the\n",
      "                      hostname system.\n",
      "\n",
      "               path_name\n",
      "                      Where path_name specifies an absolute  path  name,  then\n",
      "                      the qsub will supply the name of the host on which it is\n",
      "                      executing for the hostname\n",
      "\n",
      "               hostname:path_name\n",
      "                      Where path_name specifies an  absolute  path  name,  the\n",
      "                      path will be used as specified.  hostname.\n",
      "\n",
      "               hostname:\n",
      "                      Where  hostname  specifies the name of the host that the\n",
      "                      file should be returned to. The path will be the default\n",
      "                      file name.\n",
      "\n",
      "               If the -o option is not specified or the path_name is not spec-\n",
      "               ified or is specified and is a directory, the default file name\n",
      "               for  the standard output stream will be used.  The default name\n",
      "               has the following form:\n",
      "                   job_name.osequence_number\n",
      "               where job_name is the name of  the  job,  see  -N  option,  and\n",
      "               sequence_number is the job number assigned when the job is sub-\n",
      "               mitted.\n",
      "\n",
      "       -p priority\n",
      "               Defines the priority of the job.  The priority argument must be\n",
      "               a integer between -1024 and +1023 inclusive.  The default is no\n",
      "               priority which is equivalent to a priority of zero.\n",
      "\n",
      "       -P proxy_user[:group]\n",
      "               Proxy user for whom the job should be submitted.   This  option\n",
      "               is only available for the super user.\n",
      "\n",
      "       -q destination\n",
      "               Defines  the  destination  of the job.  The destination names a\n",
      "               queue, a server, or a queue at a server.\n",
      "\n",
      "               The qsub command will submit the script to the  server  defined\n",
      "               by  the  destination argument.  If the destination is a routing\n",
      "               queue, the job may be routed by the server to  a  new  destina-\n",
      "               tion.\n",
      "\n",
      "               If the -q option is not specified, the qsub command will submit\n",
      "               the script to the default server.  See  PBS_DEFAULT  under  the\n",
      "               Environment  Variables section on this man page and the PBS ERS\n",
      "               section 2.7.4, \"Default Server\".\n",
      "\n",
      "               If the -q option is specified, it is in one  of  the  following\n",
      "               three forms:\n",
      "                   queue\n",
      "                   @server\n",
      "                   queue@server\n",
      "\n",
      "               If  the  destination argument names a queue and does not name a\n",
      "               server, the job will be submitted to the  named  queue  at  the\n",
      "               default server.\n",
      "\n",
      "               If  the destination argument names a server and does not name a\n",
      "               queue, the job will be submitted to the default  queue  at  the\n",
      "               named server.\n",
      "\n",
      "               If  the  destination  argument names both a queue and a server,\n",
      "               the job will be submitted to  the  named  queue  at  the  named\n",
      "               server.\n",
      "\n",
      "       -r y|n  Declares whether the job is rerunable.  See the qrerun command.\n",
      "               The option argument is a single character, either y or n.\n",
      "\n",
      "               If the argument is \"y\", the job is rerunable.  If the  argument\n",
      "               is  \"n\",  the  job is not rerunable.  The default value is ’y’,\n",
      "               rerunable.\n",
      "\n",
      "       -S path_list\n",
      "               Declares the shell that interprets the job script.\n",
      "\n",
      "               The option argument path_list is in the form:\n",
      "                   path[@host][,path[@host],...]\n",
      "               Only one path may be specified for any host  named.   Only  one\n",
      "               path may be specified without the corresponding host name.  The\n",
      "               path selected will be the one with the host name  that  matched\n",
      "               the  name of the execution host.  If no matching host is found,\n",
      "               then the path specified without a host  will  be  selected,  if\n",
      "               present.\n",
      "\n",
      "               If  the  -S option is not specified, the option argument is the\n",
      "               null string, or no entry from the path_list  is  selected,  the\n",
      "               execution  will  use  the  user’s  login shell on the execution\n",
      "               host.\n",
      "\n",
      "       -t array_request\n",
      "               Specifies the task ids of a job array.  Single task arrays  are\n",
      "               allowed.\n",
      "\n",
      "               The array_request argument is an integer id or a range of inte-\n",
      "               gers. Multiple ids or id ranges can  be  combined  in  a  comma\n",
      "               delimted list. Examples : -t 1-100 or -t 1,10,50-100\n",
      "\n",
      "               An  optional slot limit can be specified to limit the amount of\n",
      "               jobs that can run concurrently in the job  array.  The  default\n",
      "               value is unlimited. The slot limit must be the last thing spec-\n",
      "               ified in the array_request and is delimited from the array by a\n",
      "               percent sign (%).\n",
      "\n",
      "               qsub script.sh -t 0-299%5\n",
      "\n",
      "               This  sets the slot limit to 5. Only 5 jobs from this array can\n",
      "               run at the same time.\n",
      "\n",
      "               Note: You can use qalter to modify slot limits on an array. The\n",
      "               server  parameter  max_slot_limit  can  be used to set a global\n",
      "               slot limit policy.\n",
      "\n",
      "       -T script_name\n",
      "               Allows for per job prologue  and  epilogue  scripts.  The  full\n",
      "               script name will be prologue.[name] or epilogue.[name]. For the\n",
      "               job submission, only request the name of the prologue  or  epi-\n",
      "               logue script.\n",
      "\n",
      "               Example: qsub -T prescript\n",
      "               Specifies to use the script prologue.prescript\n",
      "\n",
      "       -u user_list\n",
      "               Defines the user name under which the job is to run on the exe-\n",
      "               cution system.\n",
      "\n",
      "               The user_list argument is of the form:\n",
      "                   user[@host][,user[@host],...]\n",
      "               Only one user name may be given per specified host.   Only  one\n",
      "               of  the  user specifications may be supplied without the corre-\n",
      "               sponding host specification.  That user name will used for exe-\n",
      "               cution  on  any host not named in the argument list.  If unset,\n",
      "               the user list defaults to the user who is running qsub.\n",
      "\n",
      "       -v variable_list\n",
      "               Expands the list of environment variables that are exported  to\n",
      "               the job.\n",
      "\n",
      "               In  addition  to  the  variables described in the \"Description\"\n",
      "               section above, variable_list names environment  variables  from\n",
      "               the  qsub  command  environment which are made available to the\n",
      "               job when it executes.  The variable_list is a  comma  separated\n",
      "               list  of strings of the form variable or variable=value.  These\n",
      "               variables and their values are passed to the job.\n",
      "\n",
      "       -V      Declares that all environment variables in the  qsub  command’s\n",
      "               environment are to be exported to the batch job.\n",
      "\n",
      "       -w path Defines  the working directory path to be used for the job.  If\n",
      "               the -w option is not specified, the default  working  directory\n",
      "               is  the  current  directory.   This option sets the environment\n",
      "               variable PBS_O_WORKDIR.\n",
      "\n",
      "       -W additional_attributes\n",
      "               The -W option allows for the specification  of  additional  job\n",
      "               attributes.  The general syntax of the -W is in the form:\n",
      "                   -W attr_name=attr_value[,attr_name=attr_value...]\n",
      "               Note  if white space occurs anywhere within the option argument\n",
      "               string or the equal sign, \"=\", occurs within an attribute_value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               string,  then the string must be enclosed with either single or\n",
      "               double quote marks.\n",
      "\n",
      "               PBS currently supports the following attributes within  the  -W\n",
      "               option.\n",
      "\n",
      "               depend=dependency_list\n",
      "               Defines the dependency between this and other jobs.  The depen-\n",
      "               dency_list is in the form:\n",
      "               type[:argument[:argument...][,type:argument...].\n",
      "               The argument is either a numeric count or a PBS job id  accord-\n",
      "               ing  to type .  If argument is a count, it must be greater than\n",
      "               0.  If it is a job id and  not  fully  specified  in  the  form\n",
      "               seq_number.server.name,  it  will  be expanded according to the\n",
      "               default server rules which apply to job IDs on  most  commands.\n",
      "               If  argument  is  null  (the preceding colon need not be speci-\n",
      "               fied), the dependency of  the  corresponding  type  is  cleared\n",
      "               (unset).\n",
      "\n",
      "                   synccount:count\n",
      "                       This  job  is the first in a set of jobs to be executed\n",
      "                       at the same time.  Count is the  number  of  additional\n",
      "                       jobs in the set.\n",
      "\n",
      "                   syncwith:jobid\n",
      "                       This job is an additional member of a set of jobs to be\n",
      "                       executed at the same time.  In the above and  following\n",
      "                       dependency  types,  jobid  is the job identifier of the\n",
      "                       first job in the set.\n",
      "\n",
      "                   after:jobid[:jobid...]\n",
      "                       This job may be scheduled for execution  at  any  point\n",
      "                       after jobs jobid have started execution.\n",
      "\n",
      "                   afterok:jobid[:jobid...]\n",
      "                       This job may be scheduled for execution only after jobs\n",
      "                       jobid have terminated with  no  errors.   See  the  csh\n",
      "                       warning under \"Extended Description\".\n",
      "\n",
      "                   afternotok:jobid[:jobid...]\n",
      "                       This job may be scheduled for execution only after jobs\n",
      "                       jobid have terminated with errors.  See the csh warning\n",
      "                       under \"Extended Description\".\n",
      "\n",
      "                   afterany:jobid[:jobid...]\n",
      "                       This  job  may  be  scheduled  for execution after jobs\n",
      "                       jobid have terminated, with or without errors.\n",
      "\n",
      "                   on:count\n",
      "                       This job may be scheduled  for  execution  after  count\n",
      "                       dependencies  on  other jobs have been satisfied.  This\n",
      "                       form is used in conjunction  with  one  of  the  before\n",
      "                       forms, see below.\n",
      "\n",
      "                   before:jobid[:jobid...]\n",
      "                       When  this  job has begun execution, then jobs jobid...\n",
      "                       may begin.\n",
      "\n",
      "                   beforeok:jobid[:jobid...]\n",
      "                       If this job terminates execution without  errors,  then\n",
      "                       jobs  jobid...  may  begin.   See the csh warning under\n",
      "                       \"Extended Description\".\n",
      "\n",
      "                   beforenotok:jobid[:jobid...]\n",
      "                       If this job terminates execution with errors, then jobs\n",
      "                       jobid...   may   begin.   See  the  csh  warning  under\n",
      "                       \"Extended Description\".\n",
      "\n",
      "                   beforeany:jobid[:jobid...]\n",
      "                       When this job terminates execution, jobs  jobid...  may\n",
      "                       begin.\n",
      "\n",
      "                       If  any  of  the before forms are used, the jobs refer-\n",
      "                       enced by jobid must have been submitted with  a  depen-\n",
      "                       dency type of on.\n",
      "\n",
      "                   Array Dependencies\n",
      "                       It  is  now  possible to have a job depend on an array.\n",
      "                       These  dependencies  are  in  the  form   depend=array-\n",
      "                       dep:arrayid[num].  If  [num]  is  not present, then the\n",
      "                       dependencies applies to the entire array. If  [num]  is\n",
      "                       present,  then  num  means the number of jobs that must\n",
      "                       meet the condition for the dependency to be  satisfied.\n",
      "\n",
      "                   afterstartarray:arrayid[count]\n",
      "                       This job may be scheduled for execution only after jobs\n",
      "                       in arrayid have started execution.\n",
      "\n",
      "                   afterokarray:arrayid[count]\n",
      "                       This job may be scheduled for execution only after jobs\n",
      "                       in arrayid have terminated with no errors.\n",
      "\n",
      "                   afternotok:arrayid[count]\n",
      "                       This job may be scheduled for execution only after jobs\n",
      "                       in arrayid have terminated with errors.\n",
      "\n",
      "                   afteranyarray:arrayid[count]\n",
      "                       This job may be scheduled for execution after  jobs  in\n",
      "                       array id have terminated, with or without errors.\n",
      "\n",
      "                   beforestartarray:arrayid[count]\n",
      "                       This  job  may  be  scheduled for execution only before\n",
      "                       jobs in arrayid have started execution.\n",
      "\n",
      "                   beforeokarray:arrayid[count]\n",
      "                       This job may be scheduled  for  execution  only  before\n",
      "                       jobs in arrayid have terminated with no errors.\n",
      "\n",
      "                   beforenotok:arrayid[count]\n",
      "                       This  job  may  be  scheduled for execution only before\n",
      "                       jobs in arrayid have terminated with errors.\n",
      "\n",
      "                   beforeanyarray:arrayid[count]\n",
      "                       This job may be scheduled for execution before jobs  in\n",
      "                       array id have terminated, with or without errors.\n",
      "\n",
      "                       If  any  of  the before forms are used, the jobs refer-\n",
      "                       enced by jobid must have the  same  owner  as  the  job\n",
      "                       being submitted.  Otherwise, the dependency is ignored.\n",
      "\n",
      "                   Error processing of the existence, state, or  condition  of\n",
      "                   the job on which the newly submitted job is a deferred ser-\n",
      "                   vice, i.e. the check is performed after the job is  queued.\n",
      "                   If an error is detected, the new job will be deleted by the\n",
      "                   server.  Mail will be sent to the job submitter stating the\n",
      "                   error.\n",
      "\n",
      "                   Dependency examples:\n",
      "                   qsub -W depend=afterok:123.big.iron.com /tmp/script\n",
      "                   qsub      -W      depend=before:234.hunk1.com:235.hunk1.com\n",
      "                   /tmp/script\n",
      "                   qsub -W depend=afterokarray:21.tom.com[] /tmp/script\n",
      "                   qsub -W depend=beforenotokarray:22.tom.com[][5] /tmp/script\n",
      "\n",
      "               group_list=g_list\n",
      "               Defines  the  group  name  under which the job is to run on the\n",
      "               execution system.  The g_list argument is of the form:\n",
      "               group[@host][,group[@host],...]\n",
      "               Only one group name may be given per specified host.  Only  one\n",
      "               of  the group specifications may be supplied without the corre-\n",
      "               sponding host specification.  That group  name  will  used  for\n",
      "               execution  on  any host not named in the argument list.  If not\n",
      "               set, the group_list defaults to the primary group of  the  user\n",
      "               under which the job will be run.\n",
      "\n",
      "               interactive=true\n",
      "               If the interactive attribute is specified, the job is an inter-\n",
      "               active job.  The -I option is a alternative method of  specify-\n",
      "               ing this attribute.\n",
      "\n",
      "               stagein=file_list\n",
      "               stageout=file_list\n",
      "               Specifies  which  files are staged (copied) in before job start\n",
      "               or staged out after the job completes execution.  On completion\n",
      "               of the job, all staged-in and staged-out files are removed from\n",
      "               the execution system.  The file_list is in the form\n",
      "               local_file@hostname:remote_file[,...]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               regardless of the direction of the copy.  The  name  local_file\n",
      "               is  the  name of the file on the system where the job executed.\n",
      "               It may be an absolute path or relative to the home directory of\n",
      "               the  user.  The name remote_file is the destination name on the\n",
      "               host specified by hostname.  The name may be absolute or  rela-\n",
      "               tive to the user’s home directory on the destination host.  The\n",
      "               use of wildcards in the file name is not recommended.  The file\n",
      "               names  map to a remote copy program (rcp) call on the execution\n",
      "               system in the follow manner:\n",
      "               For stagein:   rcp hostname:remote_file local_file\n",
      "               For stageout:  rcp local_file hostname:remote_file\n",
      "               Data staging examples:\n",
      "               -W stagein=/tmp/input.txt@headnode:/home/user/input.txt\n",
      "               -W stageout=/tmp/output.txt@headnode:/home/user/output.txt\n",
      "               If TORQUE has been compiled with wordexp  support,  then  vari-\n",
      "               ables  can  be  used  in  the  specified paths.  Currently only\n",
      "               $PBS_JOBID, $HOME, and $TMPDIR are supported for stagein.\n",
      "\n",
      "               umask=XXX\n",
      "               Sets umask used to create stdout  and  stderr  spool  files  in\n",
      "               pbs_mom  spool directory. Values starting with 0 are treated as\n",
      "               octal values, otherwise the value is treated as a decimal umask\n",
      "               value.\n",
      "\n",
      "       -x      When  running  an interactive job, the -x flag makes it so that\n",
      "               the script won’t be parsed for PBS directives, but instead will\n",
      "               be  a  command  that  is  launched once the interactive job has\n",
      "               started. The job will terminate at the completion of this  com-\n",
      "               mand.\n",
      "\n",
      "       -X      Enables  X11 forwarding.  The DISPLAY environment variable must\n",
      "               be set.\n",
      "\n",
      "       -z      Directs that the qsub command is not to write the  job  identi-\n",
      "               fier assigned to the job to the command’s standard output.\n",
      "\n",
      "\n",
      "OPERANDS\n",
      "       The  qsub  command  accepts  a  script  operand that is the path to the\n",
      "       script of the job.  If the path is relative, it will be expanded  rela-\n",
      "       tive to the working directory of the qsub command.\n",
      "\n",
      "       If  the  script  operand  is  not provided or the operand is the single\n",
      "       character \"-\", the qsub command reads the script from  standard  input.\n",
      "       When  the  script is being read from Standard Input, qsub will copy the\n",
      "       file to a temporary file.  This temporary file is passed to the library\n",
      "       interface  routine  pbs_submit.   The temporary file is removed by qsub\n",
      "       after pbs_submit returns or upon the receipt of a  signal  which  would\n",
      "       cause qsub to terminate.\n",
      "\n",
      "STANDARD INPUT\n",
      "       The  qsub  command  reads the script for the job from standard input if\n",
      "       the script operand is missing or is the single character \"-\".\n",
      "\n",
      "INPUT FILES\n",
      "       The script file is read by the qsub command.  Qsub acts upon any direc-\n",
      "       tives found in the script.\n",
      "\n",
      "       When  the  job  is  created, a copy of the script file is made and that\n",
      "       copy cannot be modified.\n",
      "\n",
      "STANDARD OUTPUT\n",
      "       Unless the -z option is set, the job identifier  assigned  to  the  job\n",
      "       will  be written to standard output if the job is successfully created.\n",
      "\n",
      "STANDARD ERROR\n",
      "       The qsub command will write a diagnostic message to standard error  for\n",
      "       each error occurrence.\n",
      "\n",
      "ENVIRONMENT VARIABLES\n",
      "       The  values of some or all of the variables in the qsub command’s envi-\n",
      "       ronment are exported with the job, see the -v and -V options.\n",
      "\n",
      "       The environment variable PBS_DEFAULT defines the name  of  the  default\n",
      "       server.    Typically,  it corresponds to the system name of the host on\n",
      "       which the server is running.  If PBS_DEFAULT is not set, the default is\n",
      "       defined by an administrator established file.\n",
      "\n",
      "       The environment variable PBS_DPREFIX determines the prefix string which\n",
      "       identifies directives in the script.\n",
      "\n",
      "       The environment variable PBS_CLIENTRETRY defines the maximum number  of\n",
      "       seconds  qsub  will block.  See the -b option above.  Despite the name,\n",
      "       currently qsub is the only client that supports this option.\n",
      "\n",
      "TORQUE.CFG\n",
      "       The torque.cfg file, located in PBS_SERVER_HOME  (/var/spool/torque  by\n",
      "       default)  controls the behavior of the qsub command. This file contains\n",
      "       a list of parameters and values separated by whitespace\n",
      "\n",
      "       QSUBSLEEP takes an integer operand which specifies time to  sleep  when\n",
      "       running  qsub  command.   Used  to  prevent users from overwhelming the\n",
      "       scheduler.\n",
      "\n",
      "       SUBMITFILTER specifies the path to the submit filter used  to  pre-pro-\n",
      "       cess  job  submission.  The  default path is $(libexecdir)/qsub_filter,\n",
      "       which falls back to /usr/local/sbin/torque_submitfilter  for  backwards\n",
      "       compatibility. This torque.cfg parameter overrides this default.\n",
      "\n",
      "       SERVERHOST specifies the value for the PBS_SERVER environment variable\n",
      "\n",
      "       QSUBHOST specifies the hostname for the jobs QSUB_O_HOST variable\n",
      "\n",
      "       QSUBSENDUID specifies a uid to use for the jobs PBS_O_UID variable\n",
      "\n",
      "       XAUTHPATH specifies the path to xauth\n",
      "\n",
      "       CLIENTRETRY  specifies  the  integer  seconds between retry attempts to\n",
      "       communicate with pbs_server\n",
      "\n",
      "       VALIDATEGROUP set this parameter to force qsub to  verify  the  submit-\n",
      "       ter’s group id\n",
      "\n",
      "       DEFAULTCKPT  specifies  the  default  value  for  the  jobs  checkpoint\n",
      "       attribute.  The user overrides this with the -c qsub option.\n",
      "\n",
      "       VALIDATEPATH set this parameter to force qsub to validate  local  exis-\n",
      "       tence of a \"-d\" working directory\n",
      "\n",
      "       RERUNNABLEBYDEFAULT  this parameter specifies if a job is rerunnable by\n",
      "       default. The  default  is  true,  setting  this  to  false  causes  the\n",
      "       rerunnable  attribute value to be false unless the users specifies oth-\n",
      "       erwise with the -r option\n",
      "\n",
      "       FAULT_TOLERANT_BY_DEFAULT this parameter specifies if a  job  is  fault\n",
      "       tolerant  by  default.   The  default  value for the fault_tolerant job\n",
      "       attribute is false, setting this parameter to true causes  the  default\n",
      "       value  of  the attribute to be true. The user can specify their prefer-\n",
      "       ence with the -f qsub option.\n",
      "\n",
      "       For example:\n",
      "              QSUBSLEEP  2\n",
      "              RERUNNABLEBYDEFAULT  false\n",
      "\n",
      "\n",
      "\n",
      "EXTENDED DESCRIPTION\n",
      "       Script Processing:\n",
      "\n",
      "       A job script may consist of PBS  directives,  comments  and  executable\n",
      "       statements.    A  PBS  directive  provides  a  way  of  specifying  job\n",
      "       attributes in addition to the command line options.  For example:\n",
      "              :\n",
      "              #PBS -N Job_name\n",
      "              #PBS -l walltime=10:30,mem=320kb\n",
      "              #PBS -m be\n",
      "              #\n",
      "              step1 arg1 arg2\n",
      "              step2 arg3 arg4\n",
      "\n",
      "\n",
      "       The qsub command scans the lines of the script file for directives.  An\n",
      "       initial  line in the script that begins with the characters \"#!\" or the\n",
      "       character \":\" will be ignored and scanning will  start  with  the  next\n",
      "       line.   Scanning will continue until the first executable line, that is\n",
      "       a line that is not blank, not a directive line, nor a line whose  first\n",
      "       non  white  space  character is \"#\".  If directives occur on subsequent\n",
      "       lines, they will be ignored.\n",
      "\n",
      "       A line in the script file will be processed as a directive to  qsub  if\n",
      "       and  only if the string of characters starting with the first non white\n",
      "       space character on the line and of the same  length  as  the  directive\n",
      "       prefix matches the directive prefix.\n",
      "\n",
      "       The  remainder of the directive line consists of the options to qsub in\n",
      "       the same syntax as they appear on the command line.  The option charac-\n",
      "       ter is to be preceded with the \"-\" character.\n",
      "\n",
      "       If  an  option  is present in both a directive and on the command line,\n",
      "       that option and its argument, if any, will be ignored in the directive.\n",
      "       The command line takes precedence.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       If  an  option  is  present in a directive and not on the command line,\n",
      "       that option and its argument, if any, will be processed as  if  it  had\n",
      "       occurred on the command line.\n",
      "\n",
      "       The  directive  prefix string will be determined in order of preference\n",
      "       from:\n",
      "\n",
      "           The value of the -C option argument if the option is  specified  on\n",
      "           the command line.\n",
      "\n",
      "           The value of the environment variable PBS_DPREFIX if it is defined.\n",
      "\n",
      "           The four character string #PBS.\n",
      "\n",
      "       If the -C option is found in a directive in the script file, it will be\n",
      "       ignored.\n",
      "\n",
      "       User Authorization:\n",
      "\n",
      "       When  the  user submits a job from a system other than the one on which\n",
      "       the PBS Server is running, the name under which the job is to  be  exe-\n",
      "       cuted  is  selected  according to the rules listed under the -u option.\n",
      "       The user submitting the job must be authorized to run the job under the\n",
      "       execution user name.  This authorization is provided if\n",
      "\n",
      "              (1)  The  host  on which qsub is run is trusted by the execution\n",
      "                   host (see /etc/hosts.equiv),\n",
      "\n",
      "              (2)  The execution user has an .rhosts file naming  the  submit-\n",
      "                   ting user on the submitting host.\n",
      "\n",
      "       C-Shell .logout File:\n",
      "\n",
      "       The  following  warning  applies for users of the c-shell, csh.  If the\n",
      "       job is executed under the csh and a .logout file  exists  in  the  home\n",
      "       directory in which the job executes, the exit status of the job is that\n",
      "       of the .logout script, not the job script.  This may impact any  inter-\n",
      "       job  dependencies.   To preserve the job exit status, either remove the\n",
      "       .logout file or place the following line  as  the  first  line  in  the\n",
      "       .logout file\n",
      "          set EXITVAL = $status\n",
      "       and the following line as the last executable line in .logout\n",
      "          exit $EXITVAL\n",
      "\n",
      "       Interactive Jobs:\n",
      "\n",
      "       If the -I option is specified on the command line or in a script direc-\n",
      "       tive, or if the \"interactive\" job attribute declared true  via  the  -W\n",
      "       option,  -W interactive=true, either on the command line or in a script\n",
      "       directive, the job is an interactive job.  The script will be processed\n",
      "       for  directives,  but  will not be included with the job.  When the job\n",
      "       begins execution, all input to the job is from the terminal session  in\n",
      "       which qsub is running.\n",
      "\n",
      "       When  an interactive job is submitted, the qsub command will not termi-\n",
      "       nate when the job is submitted.  Qsub will remain running until the job\n",
      "       terminates, is aborted, or the user interrupts qsub with an SIGINT (the\n",
      "       control-C key).  If qsub is interrupted prior to  job  start,  it  will\n",
      "       query  if  the  user  wishes to exit.  If the user response \"yes\", qsub\n",
      "       exits and the job is aborted.\n",
      "\n",
      "       Once the interactive job has started execution,  input  to  and  output\n",
      "       from  the  job  pass  through  qsub.  Keyboard generated interrupts are\n",
      "       passed to the job.  Lines entered that begin with the tilde (’~’) char-\n",
      "       acter  and  contain  special sequences are escaped by qsub.  The recog-\n",
      "       nized escape sequences are:\n",
      "\n",
      "              ~.     Qsub terminates execution.  The batch job is also  termi-\n",
      "                     nated.\n",
      "\n",
      "              ~susp  Suspend  the  qsub  program if running under the C shell.\n",
      "                     \"susp\" is the suspend character, usually CNTL-Z.\n",
      "\n",
      "              ~asusp Suspend the input half of qsub  (terminal  to  job),  but\n",
      "                     allow  output  to  continue  to be displayed.  Only works\n",
      "                     under the C shell.   \"asusp\"  is  the  auxiliary  suspend\n",
      "                     character, usually CNTL-Y.\n",
      "\n",
      "\n",
      "EXIT STATUS\n",
      "       Upon  successful  processing,  the  qsub exit status will be a value of\n",
      "       zero.\n",
      "\n",
      "       If the qsub command fails, the command exits with a value greater  than\n",
      "       zero.\n",
      "\n",
      "SEE ALSO\n",
      "       qalter(1B),   qdel(1B),  qhold(1B),  qmove(1B),  qmsg(1B),  qrerun(1B),\n",
      "       qrls(1B),   qselect(1B),    qsig(1B),    qstat(1B),    pbs_connect(3B),\n",
      "       pbs_job_attributes(7B),                       pbs_queue_attributes(7B),\n",
      "       pbs_resources_irix5(7B),                         pbs_resources_sp2(7B),\n",
      "       pbs_resources_sunos4(7B),                    pbs_resources_unicos8(7B),\n",
      "       pbs_server_attributes(7B), and pbs_server(8B)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Local                                                                 qsub(1B)\n"
     ]
    }
   ],
   "source": [
    "man qsub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the qsub command for type 1 in this cell\n",
    "qsub -d $CSE6230_DIR -q coc-ice -l nodes=1:ppn=4:gpus=2:teslak40:exclusive_process,walltime=00:30:00 $CSE6230_DIR/utils/jupyter_notebook_job.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the qsub command for type 2 in this cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the qsub command for type 3 in this cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What have we got to work with?\n",
    "\n",
    "Now, we need to switch from a notebook running on the head node to one running on a compue node, so `File->Save and Checkpoint` this notebook and `File->Close and Halt` it.  (Now would also be a good time to `git add` and `git commit` changes to this file.)  Use one of your ineractive job scripts to connect to a compute node and run the notebook there.\n",
    "See you on the other side!\n",
    "\n",
    "---\n",
    "\n",
    "Okay, you're running on the compute node.\n",
    "\n",
    "**Compute node exercise 1 (2 pt):** Using bash scripting (`awk`, `grep`, `sed`) or any other tool you like (you could, e.g., write a python script in a separate file and call it, as long as you `git add` it), set the variables in the cell below so that the printout that follows is correct.  You script should be correct on any type of compute node.\n",
    "\n",
    "Resources: the file `/proc/cpuinfo`, the utility `nvidia-smi`; if you are very new to using a shell command line and the utilities that go with it in linux, please look at the [training slides on Linux](https://pace.gatech.edu/training) from PACE.\n",
    "\n",
    "Note: when you run a command in backticks, you can assign its value to a variable like\n",
    "\n",
    "```bash\n",
    "MY_FILES=`ls -al`\n",
    "```\n",
    "\n",
    "Also note: when ever you encounter a new program or utility `AAA` that you've never used before, `man AAA` or `AAA --help` are the first places to go if you want to know what different command line flags do.\n",
    "\n",
    "Some [one-liners](https://en.wikipedia.org/wiki/One-liner_program) that you may find useful:\n",
    "\n",
    "* `grep -P -m 1 -o -e \"(?<=XXX\\s: ).*\" YYY`: look in file `YYY` for the string \"XXX   : \" (with an arbitrary number of spaces between `XXX` and `:`) and print what comes after that on the line\n",
    "* `wc -l YYY` counts the number of lines in file `YYY`\n",
    "* most command line utilities that read files can also read the output of a previous command with a pipe `|`, for example to count the number of files in a directory:\n",
    "\n",
    "```bash\n",
    "ls -al | wc -l\n",
    "```\n",
    "\n",
    "* `grep -c \"ZZZ\" YYY` count the number of times the string `ZZZ` occurs in file `YYY`\n",
    "* Nodes without GPUs won't have the `nvidia-smi` utility.  You can tell when a utility is unavailable if `which AAA` returns an error.  If you want to write a one-liner that only runs command `AAA` when `nvidia-smi` when it's available, you can do that like this:\n",
    "\n",
    "```bash\n",
    "(which nvidia-smi &> /dev/null) && (AAA)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processor\t: 0\n",
      "vendor_id\t: GenuineIntel\n",
      "cpu family\t: 6\n",
      "model\t\t: 63\n",
      "model name\t: Intel(R) Xeon(R) CPU E5-2620 v3 @ 2.40GHz\n",
      "stepping\t: 2\n",
      "microcode\t: 54\n",
      "cpu MHz\t\t: 2400.021\n",
      "cache size\t: 15360 KB\n",
      "physical id\t: 0\n"
     ]
    }
   ],
   "source": [
    "head /proc/cpuinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: Tesla K40m (UUID: GPU-9264e1d1-674f-4941-800e-79f513dd4816)\n"
     ]
    }
   ],
   "source": [
    "nvidia-smi -L | grep '0:' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "CPU_NAME=\"Intel(R) Xeon(R) CPU E5-2620 v3 @ 2.40GHz\"\n",
    "CORE_COUNT=\"6\"\n",
    "GPU_NAME=\"Tesla K40m\"\n",
    "GPU_COUNT=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This nodes has 6 cores: its architecture is (Manufacturer, Product Id) Intel(R) Xeon(R) CPU E5-2620 v3 @ 2.40GHz\n",
      "This node has 2 GPUs: its/their architecture is (Manufacturer, Product Id) Tesla K40m\n"
     ]
    }
   ],
   "source": [
    "echo \"This nodes has ${CORE_COUNT} cores: its architecture is (Manufacturer, Product Id) ${CPU_NAME}\"\n",
    "if [[ ! $GPU_COUNT || $GPU_COUNT == 0 ]] ;  then\n",
    "    echo \"This node has no GPUs\"\n",
    "else\n",
    "    echo \"This node has ${GPU_COUNT} GPUs: its/their architecture is (Manufacturer, Product Id) ${GPU_NAME}\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute node exercise 2 (1 pt):** After you have logged out of the compute node, use whatever resources published on the web you can find to estimate the peak _single precision_ (aka FP32) flop/s of this node (you only need to do this step for one of the types of nodes, not all of them).\n",
    "\n",
    "[Resources: [ark.intel.com](https://ark.intel.com), [wikipedia:FLOPS](https://en.wikipedia.org/wiki/FLOPS), [wikichip](https://en.wikichip.org), our notebook on [processors](../../notes/processors/processors-alone.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have chosen node type __ .  The peak flop/s for this node is ____ gigaflop/s.  Here is how I calculated that:\n",
    "\n",
    "(calculation goes here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flop/s fever\n",
    "\n",
    "We've got to scratch that itch: we just want to go fast.  Okay, let's get it out of our system, and we'll look at more practical computations in future assignments.\n",
    "\n",
    "You should choose one of the node types for this task.  Because this is more complex if multiple devices are involved\n",
    "**1 bonus point** is earned for choosing a node with GPUs.\n",
    "\n",
    "**Compute node exercise 3 (2 pts):** The command below will compile and runs essentially the following computation:\n",
    "\n",
    "```C\n",
    "for (i = 0; i < Nh; i++) { /* this loop will run on the \"host\" (CPUs) */\n",
    "  for (j = 0; j < T; j++) {\n",
    "    ah[i] = ah[i] * b + c;\n",
    "  }\n",
    "}\n",
    "\n",
    "for (i = 0; i < Nd; i++) { /* this loop will run on the \"device\" (GPUs) */\n",
    "  for (j = 0; j < T; j++) {\n",
    "    ad[i] = ad[i] * b + c;\n",
    "  }\n",
    "}\n",
    "```\n",
    "And it will report the flop/s for the whole calculation.\n",
    "\n",
    "`Nh` array entries will be on the host and `Nd` entries will be on each of the devices.  Try to find values of `Nh`, `Nd`, and `T`, and (optionally) compiler optimization flags that give you the highest flop/s.  Things to consider:\n",
    "\n",
    "- Try to make your whole computation run for about a second.\n",
    "- The time reported is the maximum time for any device: if one sits idle while the other finishes, it will rob you of flop/s.\n",
    "- I suggest looking at one type of device at a time: set one of `Nh` or `Nd` to zero.  Once you've found your best flop/s for that device, optimize the other, and then try to strike a balance.\n",
    "- Experiment with the merits of putting more weight on `Nh` and `Nd` vs more weight on `T`.\n",
    "  Try to use **Little's Law** to make sure that you have enough parallelism to keep the pipelines filled.\n",
    "- You can also choose to pass the option `Bs=X` to control the thread block size for the GPU, where `X` is a power of 2 between 64 and 2048."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "icc -g -Wall -std=c99 -fPIC -O -xHost -I/usr/local/pacerepov1/cuda/8.0.44/include -qopenmp -c -o fma_prof.o fma_prof.c\n",
      "icc -g -Wall -std=c99 -fPIC -O -xHost -I/usr/local/pacerepov1/cuda/8.0.44/include -qopenmp -c -o fma_omp.o fma_omp.c\n",
      "icc -g -Wall -std=c99 -fPIC -O -xHost -I/usr/local/pacerepov1/cuda/8.0.44/include -qopenmp -c -o fma_loop_host.o fma_loop_host.c\n",
      "nvcc -ccbin=icpc -Xcompiler '-fPIC' -O -dc -o fma_cuda.o fma_cuda.cu\n",
      "nvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "nvcc -ccbin=icpc -Xcompiler '-fPIC' -O -dc -o fma_loop_dev.o fma_loop_dev.cu\n",
      "nvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "nvcc -ccbin=icpc -Xcompiler '-fPIC' -dlink  fma_cuda.o fma_loop_dev.o -o fma_cuda_link.o\n",
      "nvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "icpc -qopenmp -shared -Wl,-soname,libfma_cuda.so -o libfma_cuda.so fma_cuda_link.o fma_cuda.o fma_loop_dev.o -L/usr/local/pacerepov1/cuda/8.0.44/lib64 -Wl,-rpath,/usr/local/pacerepov1/cuda/8.0.44/lib64 -lcudart\n",
      "icpc -qopenmp -o fma_prof fma_prof.o fma_omp.o fma_loop_host.o libfma_cuda.so -Wl,-rpath,.\n",
      "OMP_PROC_BIND=spread OMP_NUM_THREADS=4  ./fma_prof 256 256 -1 -1 256 0.5 3.0\n",
      "[./fma_prof] Nh = 256, Nd = 256, T = 256, default block size\n",
      "[./fma_prof]: 9.188652e-04 elapsed seconds\n",
      "[./fma_prof]: 393216 flops executed\n",
      "[./fma_prof]: 4.279365e+08 flop/s\n"
     ]
    }
   ],
   "source": [
    "make run_fma_prof Nh=256 Nd=256 T=256 COPTFLAGS='-O -xHost' CUOPTFLAGS='-O' # modify this for peak flop/s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute Node Exercise 4 (Bonus 1 pt):** Now let's see if we can make any transformations to the code to make a difference.\n",
    "\n",
    "We will run the same program, but with fused multiply add loops that you have tried to optimize.  You should edit the files\n",
    "`fma_loop_host_opt.cu` and/or `fma_loop_dev_opt.c`: they start out exactly the same as the reference implementations used above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#include \"fma_host.h\"\n",
      "\n",
      "/* fma_loop: Fused Multiply Add loop\n",
      " *           -     -        -\n",
      " *\n",
      " * a[:] = a[:] * b + c, T times\n",
      " *\n",
      " * Inputs:\n",
      " * N : the size of the array\n",
      " * T : the number of loops\n",
      " * b : the multiplier\n",
      " * c : the shift\n",
      " *\n",
      " * Input-Outputs:\n",
      " * a : the array\n",
      " */\n",
      "void\n",
      "fma_loop_host (int N, int T, float *a, float b, float c)\n",
      "{\n",
      "  for (int i = 0; i < N; i++) {\n",
      "    for (int j = 0; j < T; j++) {\n",
      "      a[i] = a[i] * b + c;\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "cat fma_loop_host_opt.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#include \"fma_dev.h\"\n",
      "\n",
      "__global__\n",
      "void\n",
      "fma_loop_dev (int N, int T, float *a, float b, float c)\n",
      "{\n",
      "  int my_thread = threadIdx.x + blockIdx.x * blockDim.x;\n",
      "  int num_threads = gridDim.x * blockDim.x;\n",
      "\n",
      "  for (int i = my_thread; i < N; i+= num_threads) {\n",
      "    for (int j = 0; j < T; j++) {\n",
      "      a[i] = a[i] * b + c;\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "cat fma_loop_dev_opt.cu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff fma_loop_host.c fma_loop_host_opt.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff fma_loop_dev.cu fma_loop_dev_opt.cu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See if you can exploit vectorization, instruction level parallelism, and/or loop transformations to get a boost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make run_fma_prof_opt Nh=256 Nd=256 T=256 COPTFLAGS='-O -xHost' CUOPTFLAGS='-O' # modify this for peak flop/s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting this work\n",
    "\n",
    "**Workstation exercise 1 (1 pt):** When you have completed the rest of this assignment, `git add` the changes to this file, the source files you modified, and any scripts you added, and `git commit` them.  Having commited your changes, you should `git push` them to the private repository that you have on `github.gatech.edu`.\n",
    "\n",
    "Our TA Han Sol Suh will email each of you a individualized [deploy key](https://developer.github.com/v3/guides/managing-deploy-keys/) that will allow him to read the contents of your repository.  \n",
    "\n",
    "**Assignments need to be formally submitted to canvas,** but the totality of your submission on canvas should be a git revision hash or branch name indicating the version of your repository we should use to grade the assignment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
